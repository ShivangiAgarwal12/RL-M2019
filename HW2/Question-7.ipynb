{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jack's car Rental problem. Stupid_Policy defines the policy for original problem for taking actions in moving cars from one location to another. Lady_policy defines the updated Jack's car rental problem of moving the cars each night ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "import pdb\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%poisson distribution\n",
    "prob_space = {}\n",
    "def poisson(x,lam):\n",
    "    key = tuple(list((x,lam)))\n",
    "    if key not in prob_space.keys():\n",
    "        prob_space[key] = np.exp(-lam)*lam**x/np.math.factorial(x)\n",
    "    return prob_space[key]\n",
    "\n",
    "action_choice = np.arange(-5,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterated over 2 policies ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%jack environment\n",
    "class car_Rental():\n",
    "    def __init__(self,location,action):\n",
    "        self.location = location\n",
    "        self.action_space = np.arange(action)\n",
    "        self.num_state = len(location)\n",
    "        self.max_req = 11\n",
    "        self.max_ret = 11\n",
    "    \n",
    "    def reward(self,action,state_dict):\n",
    "        tot_reward = 0\n",
    "        for req_A in range(self.max_req):\n",
    "            for req_B in range(self.max_req):\n",
    "                prob_req = poisson(req_A,3)*poisson(req_B,4)\n",
    "                #update number of cars on both locations\n",
    "                car_A = min(req_A,self.location[0])\n",
    "                car_B = min(req_B,self.location[1])\n",
    "                #current reward\n",
    "                reward = 10*(car_A+car_B)\n",
    "                #final location of cars\n",
    "                car_A = min(max(self.location[0] - car_A - action, 0),20)\n",
    "                car_B = min(max(self.location[1] - car_B - action, 0),20)\n",
    "                \n",
    "                reward = reward + (-2*np.abs(action))\n",
    "                \n",
    "                for ret_A in range(self.max_ret):\n",
    "                    for ret_B in range(self.max_ret):\n",
    "                        prob_ret = poisson(ret_A,3) * poisson(ret_B,2)\n",
    "                        prob_joint = prob_req*prob_ret\n",
    "                        car_A = min((car_A + ret_A),20)\n",
    "                        car_B = min((car_B +ret_B),20)\n",
    "                        reward = prob_joint*(reward + \\\n",
    "                                             gamma*(state[tuple(list((car_A,car_B)))]))\n",
    "                        tot_reward = tot_reward + reward\n",
    "        return tot_reward\n",
    "    \n",
    "    def stupid_policy(self,action,state):\n",
    "        reward_action = []\n",
    "        for i in action:\n",
    "            tot_reward = 0\n",
    "            prob_store = []\n",
    "            for req_A in range(self.max_req):\n",
    "                for req_B in range(self.max_req):\n",
    "                    prob_req = poisson(req_A,3)*poisson(req_B,4)\n",
    "                    car_A = min(req_A,self.location[0])\n",
    "                    car_B = min(req_B,self.location[1])\n",
    "                    reward = 10*(car_A+car_B)\n",
    "                    car_A = min(max(self.location[0] - car_A - i, 0),20)\n",
    "                    car_B = min(max(self.location[1] - car_B - i,0),20)\n",
    "                    reward = reward + (-2*np.abs(i))\n",
    "                    \n",
    "                    for ret_A in range(self.max_ret):\n",
    "                        for ret_B in range(self.max_ret):\n",
    "                            prob_ret = poisson(ret_A,3) * poisson(ret_B,2)\n",
    "                            prob_joint = prob_req*prob_ret\n",
    "                            car_A = min((car_A + ret_A),20)\n",
    "                            car_B = min((car_A + ret_B),20)\n",
    "                            prob_store.append(prob_joint)\n",
    "                            reward = prob_joint*(reward + \\\n",
    "                                                 gamma*(state[tuple(list((car_A,car_B)))]))\n",
    "                            tot_reward  = tot_reward + reward\n",
    "            reward_action.append(tot_reward)\n",
    "        return action[np.argmax(reward_action)]\n",
    "    \n",
    "    def lady_policy(self,action,state):\n",
    "        reward_action = []\n",
    "        for i in action:\n",
    "            tot_reward = 0\n",
    "            prob_store = []\n",
    "            for req_A in range(self.max_req):\n",
    "                for req_B in range(self.max_req):\n",
    "                    prob_req = poisson(req_A,3) * poisson(req_B,4)\n",
    "                    car_A = min(req_A,self.location[0])\n",
    "                    car_B = min(req_B,self.location[1])\n",
    "                    reward = 10*(car_A+car_B)\n",
    "                    car_A = min(max(self.location[0] - car_A - i , 0), 20)\n",
    "                    car_B = min(max(self.location[1] - car_B - i, 0),20)\n",
    "                    reward = reward + (-2*np.abs(i))\n",
    "                    \n",
    "                    for ret_A in range(self.max_ret):\n",
    "                        for ret_B in range(self.max_ret):\n",
    "                            prob_ret = poisson(ret_A,3) * poisson(ret_B,2)\n",
    "                            prob_joint = prob_req * prob_ret\n",
    "                            j = [1,-1]\n",
    "                            for k in range(2):\n",
    "                                car_A = car_A + ret_A + j[k]\n",
    "                                car_B = car_B + ret_B - j[k]\n",
    "                                if car_A > 20 and car_A < 30:\n",
    "                                    car_A = 20\n",
    "                                else:\n",
    "                                    car_A = min((car_A + ret_A),20)\n",
    "                                    \n",
    "                                if car_B > 20 and car_B < 30:\n",
    "                                    car_B = 20\n",
    "                                else:\n",
    "                                    car_B = min((car_A + ret_A),20)\n",
    "                                prob_store.append(prob_joint)\n",
    "                                reward = reward + 4\n",
    "                                reward = prob_joint*(reward + \\\n",
    "                                                     gamma*(state[tuple(list((car_A,car_B)))]))\n",
    "                                tot_reward = tot_reward + reward\n",
    "            reward_action.append(tot_reward)\n",
    "        return action[np.argmax(reward_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%policy improvement and evaluation\n",
    "action_all = np.arange(-5,6)\n",
    "\n",
    "gamma = 0.9\n",
    "\n",
    "theta = 0.9\n",
    "\n",
    "loop = True\n",
    "\n",
    "init_state = list(itertools.product(np.arange(21),repeat = 2))\n",
    "\n",
    "state = {}\n",
    "\n",
    "for i in range(len(init_state)):\n",
    "    state[init_state[i]] = 20\n",
    "    \n",
    "policy = {}\n",
    "\n",
    "for i in range(len(init_state)):\n",
    "    policy[init_state[i]] = 0\n",
    "\n",
    "policy_stable = False\n",
    "\n",
    "while policy_stable == False:\n",
    "    while loop == True:\n",
    "        delta = 0.0\n",
    "        for i in range(len(init_state)):\n",
    "            action_choice = policy[init_state[i]]\n",
    "            \n",
    "            v = state[init_state[i]]\n",
    "            \n",
    "            agent_car = car_Rental(init_state[i],20)\n",
    "            \n",
    "            value_next = agent_car.reward(action_choice,state)\n",
    "            \n",
    "            delta = max(delta,np.abs((v-value_next)))\n",
    "            \n",
    "            state[init_state[i]] = value_next\n",
    "            \n",
    "        if delta<theta:\n",
    "            loop = False\n",
    "            \n",
    "    for i in range(len(init_state)):\n",
    "        old_action = policy[init_state[i]]\n",
    "        \n",
    "        agent_car = car_Rental(init_state[i],20)\n",
    "        \n",
    "        #pi_policy = agent_car.stupid_policy(action_all,state)\n",
    "        pi_policy = agent_car.lady_policy(action_all,state)\n",
    "        \n",
    "        if old_action == pi_policy:\n",
    "            policy_stable = True\n",
    "        else:\n",
    "            loop == True\n",
    "            policy[init_state[i]] = pi_policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
